{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Genético Para Ajuste de Parâmentros em Redes Neurais\n",
    "---\n",
    "\n",
    "Participantes: \n",
    "- Antonio Nelson Fornari Mendes Moreira\n",
    "- Luca Araujo Porto\n",
    "- Mateus\n",
    "\n",
    "\n",
    "1. [Objetivo](#objetivo)\n",
    "2. [Introdução a Redes Neurais](#introRede)\n",
    "3. [Introdução a Algoritmos Genéticos](#introGA)\n",
    "4. [Biblioteca \n",
    "\n",
    "\n",
    "## Objetivo <a name=\"objetivo\"></a>\n",
    "---\n",
    "\n",
    "O objetivo do presente projeto é avaliar o impacto de um algoritmo genético em encontrar a melhor arquitetura de uma rede neural (número de *hidden layers*, quantidade de neurônios por *hidden layers* e função de ativação) dado um problema de classificação. \n",
    "\n",
    "\n",
    "## Introdução a Redes Neurais <a name=\"introRede\"></a>\n",
    "---\n",
    "\n",
    "Esta seção tem como objetivo intruduzir o algoritmo de rede neural e, consequentemente, o conceito de problemas de classificação. **Rede Neural** é um algoritmo de inteligência aritifical, baseado no comportamento do cérebro humano, utilizado em problemas de classificação em aprendizado supervisionado.\n",
    "\n",
    "1. [Aprendizado Supervisionado](#superL)\n",
    "2. [O que é Rede Neural](#oqehRN)\n",
    "3. [O que é um Neurônio]\n",
    "\n",
    "### Aprendizado Supervisionado <a name=\"superL\"></a>\n",
    "\n",
    "Para explicar o conceito de aprendizado supervisionado utilizaremos os exemplos da [nota de aula](http://cs229.stanford.edu/notes/cs229-notes1.pdf) do professor Andrew Ng. Imagine que você queira predizer o preço de uma casa apenas usando sua área como variável. \n",
    "\n",
    "> **Objetivo**: Dado a área de uma determinada casa, gostaria de predizer seu preço.\n",
    "\n",
    "Separamos o problema em dois conjuntos, o primeiro contendo as variáveis características (*features* $\\mathscr{X}$) e as variáveis alvos (*target* $\\mathscr{Y}$), portanto, devemos encontrar uma função $h$ que consegue mapear os pontos do conjunto de características para os pontos da variável alvo. Em notação matemática: $h: \\mathscr{X}\\to\\mathscr{Y}$.\n",
    "\n",
    "A função $h$, chamado de estimador, é o **algoritmo de aprendizado**.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/2.png)\n",
    "\n",
    "Portanto, um problema é dito supervisionado quando devemos utilizar as variáveis características para predizer um conjunto dado de variáveis alvo. No entanto este tipo de problema se ramifica em outros dois tipos de problemas: Problema de Regressão e Problema de Classificação.\n",
    "\n",
    "No primeiro, as variáveis alvo são contínuas como no exemplo dos preços das casas acima, no segundo estas variáveis são discretas, que é o escopo do algortimo usado neste projeto.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/1.png)\n",
    "\n",
    "### O que é Rede Neural <a name=\"oqehRN\"></a>\n",
    "\n",
    "Rede Neural Artificial (RNA) é um algortimo de inteligência artificial baseado no comportamento do cérebro humano utilizado em problemas de classificação em aprendizados supervisionado.\n",
    "\n",
    "O cérebro um um sistema complexo, não linear e pararelo, que é capaz de organizar as estruturas constituintes (neurônios) para realizar as computações necessárias, isto é, reconhecimento de padrões, percepções e controle motoro, de forma extremamente rápida. O cérebro é capaz de aprender novas coisas de forma extremamente rápida de acordo com as experiências e comportamentos. Esta característica do cérebro é chamada de *Plasticidade*, que permite estar constantemente se adaptando a novos ambientes e situações.\n",
    "\n",
    "As RNAs podem assumir diversas arquiteturas, i.e., podem ser implementadas de diversos modos de acordo com o escopo do problema a ser resolvido, neste projeto utilizamos o Multilayer Perceptron, *Perceptron* é referete \"tipo\" do neurônio da rede, baseado no [Perceptron de Rosenblatt](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf). O algortimo RNA é, da mesma forma que o cérebro, estruturado em neurônios, que podem ou não estarem ativos num determinado instante de tempo. Estes neurônios estão dispostos em diversas camadas: Camanda de Entrada (*Input Layer IL*), Camadas Escondidas (*hidden layers HLs*) e Camada de Saída (*Output Layer OL*). Cada conexão intraneuronal contém um peso associado, representando a \"importância\" desta conexão, ao longo do *pipeline* do algoritmo os valores destes pesos sofrem ajustes de acordo com o problema tratado.\n",
    "\n",
    "A *Input Layer* contem neurônios que apenas repassam o sinal(valor) recebido sem realizar nenhuma alteração, o número de neurônios nesta camada é determinado de acordo com o número de variáveis características do problema, se, por exemplo, estivermos tratando uma imagem com *1000px* a input layer poderá ter 1000 neurônios cada qual associado a um *pixel* da imagem.\n",
    "\n",
    "A *Hidden Layer* tem uma função um pouco mais complexa que será explicada mais adiante, por hora deve-se saber que podem existir diversas *Hidden Layers* no problema, cada uma com uma quantidade específica de neurônios.\n",
    "\n",
    "A *Output Layer* tem por função receber os sinais vindos da última *Hidden Layer*, realizar um último processamento e determinar a ativação ou não do neurônios de saída. A quantidade de neurônios na saída é determinada de acordo com o número de variáveis alvo do problema.\n",
    "\n",
    "Segue um exemplo com uma RNA com apenas uma *Hidden Layer*.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/3.png)\n",
    "\n",
    "\n",
    "O algoritmo da RNA é dividido em duas etapas: *Feedforward* e *Backpropagation*. Como não é o foco do projeto, vou explicar de maneira sucinta as duas etapas.\n",
    "\n",
    "1. *Feedforward*: é o processo ao qual os sinais vindos da camada de entrada são processados \n",
    "\n",
    "\n",
    "### O que é um Neurônio\n",
    "\n",
    "Um nerônio k qualquer é visto da seguinte forma:\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/4.png)\n",
    "\n",
    "Este neurônio recebe _j_ entradas e fixamente o valor 1, em seguida, realiza uma combinação linear com os respectiovos pesos e o bias θ, da seguinte forma:\n",
    "\n",
    "$x = [x_1, x_2, ..., x_j, 1] \\quad$ **Vetor de entrada + $x_{j+1}=1$.**\n",
    "\n",
    "$w = [w_{k1},w_{k2}, ..., w_{kj}, θ] \\quad$ **Vetor de pesos + bias = $w_{k(j+1)}=θ$.**\n",
    "\n",
    "$net_k = \\displaystyle\\sum_{n=0}^{j+1} x_n \\cdot w_{kn} \\quad$ **Combinador linear**\n",
    "\n",
    "O valor calculado em $net_k$ é então aplicado à uma função de ativação definida pelo usuário:\n",
    "\n",
    "$ŷ_k = f\\_net_k = \\varphi(net_k)$\n",
    "\n",
    "No esquema representado pela imagem, o valor do erro no neurônio _k_ no n-ésimo instante, que posteriormente será usado para realizar o *backpropagation*, é definido por:\n",
    "\n",
    "$E_k(n) = (y_k - ŷ_k)²$\n",
    "\n",
    "\n",
    "- **Fonte**: [Neural Networks and Learning Machines - Simon Haykin](http://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
