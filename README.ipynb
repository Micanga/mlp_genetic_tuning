{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Genético Para Ajuste de Parâmentros em Redes Neurais\n",
    "---\n",
    "\n",
    "Participantes: \n",
    "- Antonio Nelson Fornari Mendes Moreira\n",
    "- Luca Araujo Porto Santos\n",
    "- Mateus\n",
    "\n",
    "\n",
    "1. [Objetivo](#objetivo)\n",
    "2. [Introdução a Redes Neurais](#introRede)\n",
    "3. [Introdução a Algoritmos Genéticos](#introGA)\n",
    "4. [Bibliotecas Utilizadas](#bibli)\n",
    "\n",
    "\n",
    "## Objetivo <a name=\"objetivo\"></a>\n",
    "---\n",
    "\n",
    "O objetivo do presente projeto é avaliar o impacto de um algoritmo genético em encontrar a melhor arquitetura de uma rede neural (número de *hidden layers*, quantidade de neurônios por *hidden layers* e função de ativação) dado um problema de classificação. \n",
    "\n",
    "O instanciamento e treinamento das redes neurais foram feitos em Python 3 e o algoritmo genético foi desenvolvido em C++.\n",
    "\n",
    "\n",
    "## Introdução a Redes Neurais <a name=\"introRede\"></a>\n",
    "---\n",
    "\n",
    "Esta seção tem como objetivo intruduzir o algoritmo de rede neural e, consequentemente, o conceito de problemas de classificação. **Rede Neural** é um algoritmo de inteligência aritifical, baseado no comportamento do cérebro humano, utilizado em problemas de classificação em aprendizado supervisionado.\n",
    "\n",
    "1. [Aprendizado Supervisionado](#superL)\n",
    "2. [O que é Rede Neural](#oqehRN)\n",
    "3. [O que é um Neurônio](#oqehNeu)\n",
    "4. [Função da Hidden Layer](#fcHL)\n",
    "\n",
    "### Aprendizado Supervisionado <a name=\"superL\"></a>\n",
    "\n",
    "Para explicar o conceito de aprendizado supervisionado utilizaremos os exemplos da [nota de aula](http://cs229.stanford.edu/notes/cs229-notes1.pdf) do professor Andrew Ng. Imagine que você queira predizer o preço de uma casa apenas usando sua área como variável. \n",
    "\n",
    "> **Objetivo**: Dado a área de uma determinada casa, gostaria de predizer seu preço.\n",
    "\n",
    "Separamos o problema em dois conjuntos, o primeiro contendo as variáveis características (*features* $\\mathscr{X}$) e as variáveis alvos (*target* $\\mathscr{Y}$), portanto, devemos encontrar uma função $h$ que consegue mapear os pontos do conjunto de características para os pontos da variável alvo. Em notação matemática: $h: \\mathscr{X}\\to\\mathscr{Y}$.\n",
    "\n",
    "A função $h$, chamado de estimador, é o **algoritmo de aprendizado**.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/2.png)\n",
    "\n",
    "Portanto, um problema é dito supervisionado quando devemos utilizar as variáveis características para predizer um conjunto dado de variáveis alvo. No entanto este tipo de problema se ramifica em outros dois tipos de problemas: Problema de Regressão e Problema de Classificação.\n",
    "\n",
    "No primeiro, as variáveis alvo são contínuas como no exemplo dos preços das casas acima, no segundo estas variáveis são discretas, que é o escopo do algortimo usado neste projeto.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/1.png)\n",
    "\n",
    "### O que é Rede Neural <a name=\"oqehRN\"></a>\n",
    "\n",
    "Rede Neural Artificial (RNA) é um algortimo de inteligência artificial baseado no comportamento do cérebro humano utilizado em problemas de classificação em aprendizados supervisionado.\n",
    "\n",
    "O cérebro um um sistema complexo, não linear e pararelo, que é capaz de organizar as estruturas constituintes (neurônios) para realizar as computações necessárias, isto é, reconhecimento de padrões, percepções e controle motoro, de forma extremamente rápida. O cérebro é capaz de aprender novas coisas de forma extremamente rápida de acordo com as experiências e comportamentos. Esta característica do cérebro é chamada de *Plasticidade*, que permite estar constantemente se adaptando a novos ambientes e situações.\n",
    "\n",
    "As RNAs podem assumir diversas arquiteturas, i.e., podem ser implementadas de diversos modos de acordo com o escopo do problema a ser resolvido, neste projeto utilizamos o Multilayer Perceptron, *Perceptron* é referete \"tipo\" do neurônio da rede, baseado no [Perceptron de Rosenblatt](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf). O algortimo RNA é, da mesma forma que o cérebro, estruturado em neurônios, que podem ou não estarem ativos num determinado instante de tempo. Estes neurônios estão dispostos em diversas camadas: Camanda de Entrada (*Input Layer IL*), Camadas Escondidas (*hidden layers HLs*) e Camada de Saída (*Output Layer OL*). Cada conexão intraneuronal contém um peso associado, representando a \"importância\" desta conexão, ao longo do *pipeline* do algoritmo os valores destes pesos sofrem ajustes de acordo com o problema tratado.\n",
    "\n",
    "A *Input Layer* contem neurônios que apenas repassam o sinal(valor) recebido sem realizar nenhuma alteração, o número de neurônios nesta camada é determinado de acordo com o número de variáveis características do problema, se, por exemplo, estivermos tratando uma imagem com *1000px* a input layer poderá ter 1000 neurônios cada qual associado a um *pixel* da imagem.\n",
    "\n",
    "A *Hidden Layer* tem uma função um pouco mais complexa que será explicada mais adiante, por hora deve-se saber que podem existir diversas *Hidden Layers* no problema, cada uma com uma quantidade específica de neurônios.\n",
    "\n",
    "A *Output Layer* tem por função receber os sinais vindos da última *Hidden Layer*, realizar um último processamento e determinar a ativação ou não do neurônios de saída. A quantidade de neurônios na saída é determinada de acordo com o número de variáveis alvo do problema.\n",
    "\n",
    "Segue um exemplo com uma RNA com apenas uma *Hidden Layer*.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/3.png)\n",
    "\n",
    "\n",
    "O algoritmo da RNA é dividido em duas etapas: *Feedforward* e *Backpropagation*. Como não é o foco do projeto, vou explicar de maneira sucinta as duas etapas.\n",
    "\n",
    "1. *Feedforward*: é o processo ao qual os sinais vindos da camada de entrada são processados pelos neurônios das camadas escondidas e posteriormente pelos neurônios de saída. Cada neurônio aplica o peso sináptico associado ao valor de entrada mais um bias (deslocador linear) e, por fim, uma função de ativação determina se o neurônio ativará ou não.\n",
    "\n",
    "2. *Backpropagation*: é o processo pelo qual, através dos erros de classificação, é possível corrigir os pesos sinápticos associados a cada neurônio.\n",
    "\n",
    "\n",
    "### O que é um Neurônio <a name=\"oqehNeu\"></a>\n",
    "\n",
    "Um nerônio k qualquer é visto da seguinte forma:\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/4.png)\n",
    "\n",
    "Este neurônio recebe _j_ entradas e fixamente o valor 1, em seguida, realiza uma combinação linear com os respectiovos pesos e o bias θ, da seguinte forma:\n",
    "\n",
    "$x = [x_1, x_2, ..., x_j, 1] \\quad$ **Vetor de entrada + $x_{j+1}=1$.**\n",
    "\n",
    "$w = [w_{k1},w_{k2}, ..., w_{kj}, θ] \\quad$ **Vetor de pesos + bias = $w_{k(j+1)}=θ$.**\n",
    "\n",
    "$net_k = \\displaystyle\\sum_{n=0}^{j+1} x_n \\cdot w_{kn} \\quad$ **Combinador linear**\n",
    "\n",
    "O valor calculado em $net_k$ é então aplicado à uma função de ativação definida pelo usuário:\n",
    "\n",
    "$ŷ_k = f\\_net_k = \\varphi(net_k)$\n",
    "\n",
    "No esquema representado pela imagem, o valor do erro no neurônio _k_ no n-ésimo instante, que posteriormente será usado para realizar o *backpropagation*, é definido por:\n",
    "\n",
    "$E_k(n) = (y_k - ŷ_k)²$\n",
    "\n",
    "\n",
    "### Função da Hidden Layer <a name=\"fcHL\"></a>\n",
    "\n",
    "De forma breve, as *Hidden Layers* têm como função determinar *hiperplanos* separadores no problema. Como tratamos de um problema de classificação, buscamos, através do algoritmo, determinar a região do espaço ao qual cada ponto (amostra do conjunto variáveis característica) pertence, então cada neurônio na camada escondida \"desenhará\" um hiperplano no espaço separando entre as classes (variáveis alvo) do problema, como mostra a imagem a seguir. A dimensão (R², R³, R⁴, ...) do hiperplano é determinado pelo número de *features* do problema, por exemplo, um problema com duas características determinará uma reta no espaço.\n",
    "\n",
    "![img](https://raw.githubusercontent.com/Micanga/mlp_genetic_tuning/master/imgs/5.png)\n",
    "\n",
    "\n",
    "## Introdução a Algoritmos Genéticos\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Bibliotecas Utilizadas <a name=\"bibli\"></a>\n",
    "---\n",
    "Bibliotecas de Python 3 (neste projeto 3.8.2 - GCC 9.3.0) utilizadas:\n",
    "\n",
    "0. [pip3](https://pip.pypa.io/en/stable/installing/): gerenciador de pacotes python.\n",
    "\n",
    "1. [numpy](https://numpy.org/): bibliteca para manipulações matemáticas.\n",
    "\n",
    "```bash\n",
    "pip3 install -U numpy\n",
    "```  \n",
    "2. [scikit-learn](https://scikit-learn.org/stable/): bilioteca de aprendizado de máquina.\n",
    "\n",
    "```bash\n",
    "pip3 install -U scikit-learn\n",
    "```\n",
    "3. [matplotlib](https://matplotlib.org/): biblioteca de visualização computacional.\n",
    "\n",
    "```bash\n",
    "pip3 install -U matplotlib\n",
    "```\n",
    "\n",
    "## Como executar <a name=\"exec\"></a>\n",
    "\n",
    "Para executar é necessário utilizar o Makefilee\n",
    "\n",
    "```bash\n",
    "make\n",
    "./main\n",
    "```\n",
    "\n",
    "\n",
    "**Fontes**:  \n",
    "1. [Neural Networks and Learning Machines - Simon Haykin](http://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf)  \n",
    "2. [Multilayer-Perceptron-Basics](https://github.com/antonioMoreira/Multilayer-Perceptron-Basics): Para mais informações sobre o funcionamento da MLP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
